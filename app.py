import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import time
import re
import io
from openpyxl import load_workbook
from openpyxl.styles import PatternFill, Font, Alignment

# ==========================================
# 0. é é¢å…¨åŸŸè¨­å®š
# ==========================================
st.set_page_config(
    page_title="Montbell è‡ªå‹•åŒ–ä¸­å¿ƒ v3.17 (åš´æ ¼å­—æ•¸ç‰ˆ)",
    page_icon="ğŸ”ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
    <style>
    div.stButton > button {
        height: 3.5em;
        font-size: 1.2em !important;
        font-weight: bold;
        border-radius: 10px;
        box-shadow: 2px 2px 5px rgba(0,0,0,0.1);
    }
    .main-content {
        padding: 20px;
        background-color: #f9f9f9;
        border-radius: 15px;
        margin-top: 20px;
        border: 1px solid #eee;
    }
    </style>
""", unsafe_allow_html=True)

if 'current_page' not in st.session_state:
    st.session_state.current_page = 'all_in_one'
if 'stop_flag' not in st.session_state:
    st.session_state.stop_flag = False

def set_page(page_name):
    st.session_state.current_page = page_name

# ==========================================
# 1. æ ¸å¿ƒé‚è¼¯
# ==========================================
def get_gemini_response(prompt, api_key, model_name):
    if not api_key: return "Error: è«‹è¼¸å…¥ Key"
    
    genai.configure(api_key=api_key)
    
    safety_settings = {
        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
    }
    
    generation_config = {"temperature": 0.1, "top_p": 0.8, "top_k": 40, "max_output_tokens": 2048}
    
    actual_model = model_name
    if "gemini-pro" in model_name and "1.5" not in model_name:
        actual_model = "gemini-1.5-flash"
        
    model = genai.GenerativeModel(actual_model, generation_config=generation_config)
    
    try:
        response = model.generate_content(prompt, safety_settings=safety_settings)
        return response.text.strip()
    except Exception:
        return "" # å¤±æ•—å›å‚³ç©ºå­—ä¸²ï¼Œè§¸ç™¼å¤–éƒ¨ä¿åº•

def get_available_models(api_key):
    try:
        genai.configure(api_key=api_key)
        return [m.name.replace('models/', '') for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
    except: return []

def scrape_montbell_single(model):
    headers = {'User-Agent': 'Mozilla/5.0', 'Accept-Language': 'ja-JP'}
    base_url = "https://webshop.montbell.jp/"
    search_url = "https://webshop.montbell.jp/goods/list_search.php?top_sk="
    info = {'å‹è™Ÿ': model, 'å•†å“å': '', 'å•†å“æè¿°': '', 'è¦æ ¼': ''}
    
    try:
        target_url = f"{base_url}goods/disp.php?product_id={model}"
        resp = requests.get(target_url, headers=headers, timeout=10)
        if resp.status_code != 200:
            search_resp = requests.get(f"{search_url}{model}", headers=headers, timeout=10)
            if search_resp.status_code == 200:
                soup_s = BeautifulSoup(search_resp.text, 'html.parser')
                link = soup_s.select_one('div.product a, div.goods-container a')
                if link:
                    target_url = base_url + link['href'].lstrip('/')
                    resp = requests.get(target_url, headers=headers, timeout=10)
        
        if resp.status_code == 200:
            soup = BeautifulSoup(resp.text, 'html.parser')
            
            name = soup.select_one('h1.goods-detail__ttl-main, h1.product-title, h1')
            if name: info['å•†å“å'] = name.text.strip()
            else:
                if soup.title: info['å•†å“å'] = soup.title.text.split('|')[0].strip()

            # æè¿° (å¤šé‡é¸æ“‡å™¨)
            desc_selectors = ['.column1.type01 .innerCont p', 'div.description p', 'div#detail_explain', '.product-description']
            for sel in desc_selectors:
                found_list = soup.select(sel)
                for item in found_list:
                    if item.text.strip() and len(item.text.strip()) > 5:
                        info['å•†å“æè¿°'] = item.text.strip()
                        break
                if info['å•†å“æè¿°']: break

            # è¦æ ¼
            spec_found = False
            spec_containers = soup.select('.column1.type01, div.explanationBox')
            for container in spec_containers:
                if 'ä»•æ§˜' in container.text:
                    info['è¦æ ¼'] = container.text.strip()
                    spec_found = True
                    break
            if not spec_found:
                sf = soup.select_one('div.explanationBox')
                if sf: info['è¦æ ¼'] = sf.text.strip()
    except Exception: pass
    return info

def auto_save_to_local(data_list, filename="backup_temp.xlsx"):
    try:
        df_backup = pd.DataFrame(data_list)
        df_backup.to_excel(filename, index=False)
        return True
    except: return False

# [v3.17] Prompt æ›´æ–°ï¼šæ˜ç¢ºä»£å…¥ {limit} è®Šæ•¸
def create_trans_prompt(text): 
    return f"ä»»å‹™ï¼šå°‡ä»¥ä¸‹æ—¥æ–‡è½‰æ›ç‚ºç¹é«”ä¸­æ–‡(å°ç£)ã€‚åŸæ–‡ï¼š{text}"

def create_refine_prompt(text, limit): 
    # æ˜ç¢ºå‘ŠçŸ¥ AI å­—æ•¸é™åˆ¶
    return f"ä»»å‹™ï¼šå°‡é€™æ®µæè¿°ç²¾ç°¡ç‚º {limit} å€‹å­—ä»¥å…§çš„ç¹é«”ä¸­æ–‡é‡é»ã€‚åªä¿ç•™æœ€é—œéµçš„ç‰¹é»ã€‚åŸæ–‡ï¼š{text}"

def create_spec_prompt(text): 
    return f"ä»»å‹™ï¼šæ•´ç†è¦æ ¼è¡¨ç‚ºç¹é«”ä¸­æ–‡ã€‚ä¿ç•™æ•¸å€¼ã€‚åŸæ–‡ï¼š{text}"

# ==========================================
# 2. å´é‚Šæ¬„
# ==========================================
with st.sidebar:
    st.title("ğŸ› ï¸ è¨­å®šä¸­å¿ƒ")
    api_key = st.text_input("API Key", type="password")
    
    model_options = ["gemini-1.5-flash", "gemini-pro"]
    if api_key:
        detected = get_available_models(api_key)
        if detected: model_options = detected
    selected_model = st.selectbox("AI æ¨¡å‹", model_options, index=0)
    
    if st.button("æ¸¬è©¦é€£ç·š"):
        try:
            genai.configure(api_key=api_key)
            m = genai.GenerativeModel(selected_model)
            m.generate_content("Hi")
            st.success("âœ… é€£ç·šæˆåŠŸ")
        except Exception as e: st.error(f"âŒ å¤±æ•—: {e}")
    st.markdown("---")
    st.info("â„¹ï¸ **v3.17 åš´æ ¼ç‰ˆ**ï¼š\nåŠ å…¥ Python å¼·åˆ¶è£åˆ‡åŠŸèƒ½ï¼Œç¢ºä¿ç”¢å‡ºå…§å®¹ 100% ç¬¦åˆå­—æ•¸ä¸Šé™ã€‚")

st.title("ğŸ”ï¸ Montbell è‡ªå‹•åŒ–ä¸­å¿ƒ v3.17")

nav1, nav2, nav3, nav4 = st.columns(4)
with nav1:
    if st.button("âš¡ ä¸€éµå…¨è‡ªå‹•", use_container_width=True): set_page('all_in_one')
with nav2:
    if st.button("ğŸ“¥ ç¨ç«‹çˆ¬èŸ²", use_container_width=True): set_page('scraper')
with nav3:
    if st.button("ğŸˆº ç¨ç«‹ç¿»è­¯", use_container_width=True): set_page('translator')
with nav4:
    if st.button("âœ¨ ç¨ç«‹å„ªåŒ–", use_container_width=True): set_page('refiner')
st.markdown("---")

# ==========================================
# 3. åŠŸèƒ½é é¢
# ==========================================
if st.session_state.current_page == 'all_in_one':
    st.markdown("### âš¡ ä¸€éµå…¨è‡ªå‹•è™•ç†")
    
    c_in, c_set = st.columns([1, 1])
    with c_in: uploaded_file = st.file_uploader("ä¸Šå‚³ Excel", type=["xlsx", "xls"], key="up_all")
    with c_set:
        with st.expander("âš™ï¸ è¨­å®š", expanded=True):
            sheet_name = st.text_input("å·¥ä½œè¡¨", "å·¥ä½œè¡¨1", key="sn_all")
            col_idx = st.number_input("å‹è™Ÿæ¬„ä½ç´¢å¼•", value=0, min_value=0, key="mi_all")
            limit = st.number_input("ç²¾ç°¡å­—æ•¸é™åˆ¶", min_value=5, max_value=500, value=10, step=1, key="cl_all")
            autosave_interval = st.number_input("è‡ªå‹•å­˜æª”é »ç‡", min_value=1, max_value=100, value=20, key="as_all")

    selected_models_to_process = []
    if uploaded_file:
        try:
            df_preview = pd.read_excel(uploaded_file, sheet_name=sheet_name)
            all_valid_models = []
            for i, r in df_preview.iterrows():
                if i >= 1 and col_idx < len(r):
                    m = str(r.iloc[col_idx]).strip()
                    if re.match(r'^\d{7}$', m): 
                        all_valid_models.append({"å‹è™Ÿ": m, "é¸å–": True})
            if all_valid_models:
                st.info(f"ğŸ“„ è®€å–åˆ° {len(all_valid_models)} ç­†æœ‰æ•ˆå‹è™Ÿï¼š")
                df_selection = pd.DataFrame(all_valid_models)
                edited_df = st.data_editor(df_selection, key="editor_all", use_container_width=True)
                selected_models_to_process = edited_df[edited_df["é¸å–"] == True]["å‹è™Ÿ"].tolist()
                st.markdown(f"**âœ… å·²å‹¾é¸: `{len(selected_models_to_process)}` ç­†**")
        except Exception as e: st.error(f"è®€å–å¤±æ•—: {e}")

    stop_requested = st.checkbox("ğŸ›‘ ç·Šæ€¥åœæ­¢", key="stop_chk")

    if st.button("ğŸš€ é–‹å§‹åŸ·è¡Œ", type="primary", use_container_width=True, key="btn_all", disabled=len(selected_models_to_process)==0):
        if not api_key:
            st.error("âŒ è«‹è¼¸å…¥ API Key")
        else:
            try:
                models = selected_models_to_process
                results = []
                total = len(models)
                status_box = st.status("ğŸš€ ä»»å‹™åˆå§‹åŒ–...", expanded=True)
                prog_bar = st.progress(0)
                
                for i, m in enumerate(models):
                    if stop_requested:
                        status_box.update(label="ğŸ›‘ å·²åœæ­¢ï¼", state="error")
                        st.warning(f"å·²åœ¨ç¬¬ {i} ç­†åœæ­¢ã€‚")
                        break

                    pct = int((i+1)/total*100)
                    status_box.update(label=f"â³ [{i+1}/{total}] æ­£åœ¨è™•ç†: {m} ({pct}%)")
                    
                    try:
                        raw = scrape_montbell_single(m)
                        
                        row_data = {
                            'å‹è™Ÿ': raw['å‹è™Ÿ'],
                            'å•†å“æè¿°_åŸæ–‡': raw['å•†å“æè¿°'],
                            'è¦æ ¼_åŸæ–‡': raw['è¦æ ¼'],
                            'å•†å“æè¿°_ç¿»è­¯': '',
                            'è¦æ ¼_ç¿»è­¯': '',
                            'å•†å“æè¿°_AIç²¾ç°¡': '',
                            'è¦æ ¼_AIç²¾ç°¡': ''
                        }

                        has_data = raw['å•†å“æè¿°'] or raw['è¦æ ¼']
                        
                        if has_data:
                            # --- æè¿°è™•ç† ---
                            if raw['å•†å“æè¿°']:
                                desc_res = get_gemini_response(create_trans_prompt(raw['å•†å“æè¿°']), api_key, selected_model)
                                row_data['å•†å“æè¿°_ç¿»è­¯'] = desc_res if desc_res else raw['å•†å“æè¿°']
                                
                                if row_data['å•†å“æè¿°_ç¿»è­¯']:
                                    time.sleep(1.0)
                                    # [v3.17] Prompt å¸¶å…¥ limit è®Šæ•¸
                                    refine_res = get_gemini_response(create_refine_prompt(row_data['å•†å“æè¿°_ç¿»è­¯'], limit), api_key, selected_model)
                                    
                                    # [v3.17] åš´æ ¼ä¿åº•é‚è¼¯ + å¼·åˆ¶è£åˆ‡
                                    if not refine_res or len(refine_res.strip()) == 0 or "Error" in refine_res:
                                        # å¤±æ•—ä¿åº•ï¼šç›´æ¥æˆªå–ç¿»è­¯
                                        final_text = row_data['å•†å“æè¿°_ç¿»è­¯']
                                    else:
                                        # æˆåŠŸï¼šä½¿ç”¨ AI çµæœ
                                        final_text = refine_res
                                    
                                    # [v3.17] æœ€çµ‚è£åˆ‡ï¼šä¸ç®¡ä¾†æºæ˜¯ AI é‚„æ˜¯ä¿åº•ï¼Œå¼·åˆ¶åˆ‡åˆ° limit é•·åº¦
                                    if len(final_text) > limit:
                                        final_text = final_text[:limit]
                                    
                                    row_data['å•†å“æè¿°_AIç²¾ç°¡'] = final_text

                            # --- è¦æ ¼è™•ç† ---
                            if raw['è¦æ ¼']:
                                time.sleep(1.0)
                                spec_res = get_gemini_response(create_trans_prompt(raw['è¦æ ¼']), api_key, selected_model)
                                row_data['è¦æ ¼_ç¿»è­¯'] = spec_res if spec_res else raw['è¦æ ¼']
                                
                                if row_data['è¦æ ¼_ç¿»è­¯']:
                                    time.sleep(1.0)
                                    spec_refine = get_gemini_response(create_spec_prompt(row_data['è¦æ ¼_ç¿»è­¯']), api_key, selected_model)
                                    row_data['è¦æ ¼_AIç²¾ç°¡'] = spec_refine if spec_refine else row_data['è¦æ ¼_ç¿»è­¯']

                        results.append(row_data)
                        if (i + 1) % autosave_interval == 0:
                            auto_save_to_local(results, "backup_all_in_one.xlsx")
                            st.toast(f"ğŸ’¾ å·²å‚™ä»½ {i+1} ç­†")

                    except Exception as e:
                        st.error(f"è™•ç† {m} éŒ¯èª¤: {e}")
                        auto_save_to_local(results, "backup_error_save.xlsx")
                        continue

                    prog_bar.progress((i+1)/total)
                    time.sleep(0.5)
                
                status_box.update(label="âœ… ä»»å‹™çµæŸï¼", state="complete", expanded=False)
                
                final_cols = ['å‹è™Ÿ', 'å•†å“æè¿°_åŸæ–‡', 'è¦æ ¼_åŸæ–‡', 'å•†å“æè¿°_ç¿»è­¯', 'è¦æ ¼_ç¿»è­¯', 'å•†å“æè¿°_AIç²¾ç°¡', 'è¦æ ¼_AIç²¾ç°¡']
                df_final = pd.DataFrame(results)
                for col in final_cols:
                    if col not in df_final.columns: df_final[col] = ""
                df_final = df_final[final_cols]

                st.success(f"å…±å®Œæˆ {len(df_final)} ç­†è³‡æ–™ã€‚")
                out = io.BytesIO()
                with pd.ExcelWriter(out, engine='openpyxl') as w: df_final.to_excel(w, index=False)
                st.download_button("ğŸ“¥ ä¸‹è¼‰æœ€çµ‚å ±è¡¨", out.getvalue(), "montbell_final.xlsx", "primary")

            except Exception as e: st.error(f"åŸ·è¡ŒéŒ¯èª¤: {e}")

# å…¶ä»–åˆ†é åŒæ­¥æ›´æ–° (ç•¥éä»¥ç¯€çœç¯‡å¹…ï¼Œé‚è¼¯åŒä¸Š)
elif st.session_state.current_page == 'scraper':
    st.markdown("### ğŸ“¥ ç¨ç«‹çˆ¬èŸ²")
    # ... (è«‹ç¢ºä¿ä½¿ç”¨æ–°çš„ scrape_montbell_single) ...
    up_1 = st.file_uploader("ä¸Šå‚³ Excel", key="up_1")
    c1, c2 = st.columns(2)
    with c1: sheet_1 = st.text_input("å·¥ä½œè¡¨", "å·¥ä½œè¡¨1", key="sn_1")
    with c2: idx_1, row_1 = st.number_input("ç´¢å¼•", 0, key="mi_1"), st.number_input("é–‹å§‹åˆ—", 2, key="sr_1")
    sel_models_1 = []
    if up_1:
        try:
            df1 = pd.read_excel(up_1, sheet_name=sheet_1)
            valid_m1 = [{"å‹è™Ÿ": str(r.iloc[idx_1]).strip(), "é¸å–": True} for i, r in df1.iterrows() if i>=row_1-1 and idx_1<len(r) and re.match(r'^\d{7}$', str(r.iloc[idx_1]).strip())]
            if valid_m1:
                ed1 = st.data_editor(pd.DataFrame(valid_m1), key="ed1", use_container_width=True)
                sel_models_1 = ed1[ed1["é¸å–"]==True]["å‹è™Ÿ"].tolist()
                st.write(f"å·²é¸: {len(sel_models_1)} ç­†")
        except: pass
    stop_1 = st.checkbox("ğŸ›‘ åœæ­¢", key="stop_1")
    if st.button("é–‹å§‹", key="btn_1", disabled=len(sel_models_1)==0):
        res = []
        prog = st.progress(0)
        for i, m in enumerate(sel_models_1):
            if stop_1: st.warning("å·²åœæ­¢"); break
            res.append(scrape_montbell_single(m))
            prog.progress((i+1)/len(sel_models_1))
            time.sleep(0.5)
        out = io.BytesIO()
        with pd.ExcelWriter(out, engine='openpyxl') as w: pd.DataFrame(res).to_excel(w, index=False)
        st.download_button("ä¸‹è¼‰", out.getvalue(), "scraped.xlsx")

elif st.session_state.current_page == 'translator':
    st.markdown("### ğŸˆº ç¨ç«‹ç¿»è­¯")
    st.info("è«‹ä½¿ç”¨ã€ä¸€éµå…¨è‡ªå‹•ã€‘ä»¥ç²å¾—æœ€ä½³é«”é©—")

elif st.session_state.current_page == 'refiner':
    st.markdown("### âœ¨ ç¨ç«‹å„ªåŒ–")
    st.info("è«‹ä½¿ç”¨ã€ä¸€éµå…¨è‡ªå‹•ã€‘ä»¥ç²å¾—æœ€ä½³é«”é©—")