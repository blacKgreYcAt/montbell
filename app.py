import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import time
import re
import io
from openpyxl import load_workbook
from openpyxl.styles import PatternFill, Font, Alignment

# ==========================================
# 0. é é¢å…¨åŸŸè¨­å®š
# ==========================================
st.set_page_config(
    page_title="Montbell è‡ªå‹•åŒ–ä¸­å¿ƒ v3.10 (ç¯©é¸ç‰ˆ)",
    page_icon="ğŸ”ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
    <style>
    div.stButton > button {
        height: 3.5em;
        font-size: 1.2em !important;
        font-weight: bold;
        border-radius: 10px;
        box-shadow: 2px 2px 5px rgba(0,0,0,0.1);
    }
    .main-content {
        padding: 20px;
        background-color: #f9f9f9;
        border-radius: 15px;
        margin-top: 20px;
        border: 1px solid #eee;
    }
    </style>
""", unsafe_allow_html=True)

if 'current_page' not in st.session_state:
    st.session_state.current_page = 'all_in_one'
if 'stop_flag' not in st.session_state:
    st.session_state.stop_flag = False

def set_page(page_name):
    st.session_state.current_page = page_name

# ==========================================
# 1. æ ¸å¿ƒé‚è¼¯èˆ‡å·¥å…·å‡½å¼
# ==========================================
def get_gemini_response(prompt, api_key, model_name, retry=True):
    if not api_key: return "Error: è«‹è¼¸å…¥ Key"
    try:
        genai.configure(api_key=api_key)
        safety_settings = {
            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
        }
        generation_config = {"temperature": 0.2, "top_p": 0.8, "top_k": 40, "max_output_tokens": 2048}
        model = genai.GenerativeModel(model_name.strip(), generation_config=generation_config)
        response = model.generate_content(prompt, safety_settings=safety_settings)
        try:
            return response.text.strip()
        except ValueError:
            if retry:
                simple_prompt = f"Translate the following Japanese text to Traditional Chinese (Taiwan): {prompt.split('åŸæ–‡ï¼š')[-1]}"
                return get_gemini_response(simple_prompt, api_key, model_name, retry=False)
            return "Error: å…§å®¹è¢«å®‰å…¨æ€§æ””æˆª"
    except Exception as e:
        return f"Error: {str(e)}"

def get_available_models(api_key):
    try:
        genai.configure(api_key=api_key)
        return [m.name.replace('models/', '') for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
    except: return []

def scrape_montbell_single(model):
    """çˆ¬èŸ²ï¼šåªæŠ“å– æ¨™é¡Œã€æè¿°ã€è¦æ ¼"""
    headers = {'User-Agent': 'Mozilla/5.0', 'Accept-Language': 'ja-JP'}
    base_url = "https://webshop.montbell.jp/"
    search_url = "https://webshop.montbell.jp/goods/list_search.php?top_sk="
    info = {'å‹è™Ÿ': model, 'å•†å“å': '', 'å•†å“æè¿°': '', 'è¦æ ¼': '', 'å•†å“URL': ''}
    try:
        target_url = f"{base_url}goods/disp.php?product_id={model}"
        resp = requests.get(target_url, headers=headers, timeout=10)
        if resp.status_code != 200:
            search_resp = requests.get(f"{search_url}{model}", headers=headers, timeout=10)
            if search_resp.status_code == 200:
                soup_s = BeautifulSoup(search_resp.text, 'html.parser')
                link = soup_s.select_one('div.product a, div.goods-container a')
                if link:
                    target_url = base_url + link['href'].lstrip('/')
                    resp = requests.get(target_url, headers=headers, timeout=10)
        if resp.status_code == 200:
            soup = BeautifulSoup(resp.text, 'html.parser')
            info['å•†å“URL'] = target_url
            name = soup.select_one('h1.goods-detail__ttl-main, h1.product-title, h1')
            if name: info['å•†å“å'] = name.text.strip()
            else:
                if soup.title: info['å•†å“å'] = soup.title.text.split('|')[0].strip()
            desc = soup.select('.column1.type01 .innerCont p')
            if desc: info['å•†å“æè¿°'] = desc[0].text.strip()
            spec = soup.select('.column1.type01, div.explanationBox')
            for s in spec:
                if 'ä»•æ§˜' in s.text: info['è¦æ ¼'] = s.text.strip()
            if not info['è¦æ ¼']:
                sf = soup.select_one('div.explanationBox')
                if sf: info['è¦æ ¼'] = sf.text.strip()
    except Exception: pass
    return info

def auto_save_to_local(data_list, filename="backup_temp.xlsx"):
    try:
        df_backup = pd.DataFrame(data_list)
        df_backup.to_excel(filename, index=False)
        return True
    except: return False

# Prompt Generators
def create_trans_prompt(text): return f"è§’è‰²ï¼šå°ˆæ¥­æˆ¶å¤–ç”¨å“è­¯è€…(å°ç£)ã€‚ä»»å‹™ï¼šå°‡æ—¥æ–‡ç¿»è­¯ç‚ºç¹é«”ä¸­æ–‡ã€‚åŸå‰‡ï¼š1.å°ˆæœ‰åè©å°å¼åŒ–ã€‚2.èªæ°£è‡ªç„¶ã€‚3.ä¸è§£é‡‹ã€‚åŸæ–‡ï¼š{text}"
def create_refine_prompt(text, limit): return f"ä»»å‹™ï¼šæå–è³£é»ä¸¦ç²¾ç°¡ã€‚é™åˆ¶ï¼š{limit}å­—å…§ã€‚åŸæ–‡ï¼š{text}"
def create_spec_prompt(text): return f"ä»»å‹™ï¼šå„ªåŒ–è¦æ ¼è¡¨ã€‚è¦å‰‡ï¼šä¿ç•™ã€ã€‘æ¨™é¡Œï¼Œå»é™¤è´…å­—ï¼Œç¸®å¯«ï¼Œä¿æŒæ›è¡Œã€‚åŸæ–‡ï¼š{text}"

# ==========================================
# 2. å´é‚Šæ¬„èˆ‡å°èˆª
# ==========================================
with st.sidebar:
    st.title("ğŸ› ï¸ è¨­å®šä¸­å¿ƒ")
    api_key = st.text_input("API Key", type="password")
    
    model_options = ["gemini-pro"]
    if api_key:
        detected = get_available_models(api_key)
        if detected: model_options = detected
    selected_model = st.selectbox("AI æ¨¡å‹", model_options, index=0)
    
    if st.button("æ¸¬è©¦é€£ç·š"):
        try:
            genai.configure(api_key=api_key)
            m = genai.GenerativeModel(selected_model)
            m.generate_content("Hi")
            st.success("âœ… é€£ç·šæˆåŠŸ")
        except Exception as e: st.error(f"âŒ å¤±æ•—: {e}")
        
    st.markdown("---")
    st.info("â„¹ï¸ **v3.10 ç¯©é¸ç‰ˆ**ï¼š\nä¸Šå‚³æª”æ¡ˆå¾Œï¼Œæ‚¨ç¾åœ¨å¯ä»¥å…ˆå‹¾é¸æƒ³è¦è™•ç†çš„é …ç›®ï¼Œå†é–‹å§‹åŸ·è¡Œã€‚")

st.title("ğŸ”ï¸ Montbell è‡ªå‹•åŒ–ä¸­å¿ƒ v3.10")

nav1, nav2, nav3, nav4 = st.columns(4)
with nav1:
    if st.button("âš¡ ä¸€éµå…¨è‡ªå‹•", use_container_width=True): set_page('all_in_one')
with nav2:
    if st.button("ğŸ“¥ ç¨ç«‹çˆ¬èŸ²", use_container_width=True): set_page('scraper')
with nav3:
    if st.button("ğŸˆº ç¨ç«‹ç¿»è­¯", use_container_width=True): set_page('translator')
with nav4:
    if st.button("âœ¨ ç¨ç«‹å„ªåŒ–", use_container_width=True): set_page('refiner')
st.markdown("---")

# ==========================================
# 3. åŠŸèƒ½é é¢å¯¦ä½œ
# ==========================================

if st.session_state.current_page == 'all_in_one':
    st.markdown("### âš¡ ä¸€éµå…¨è‡ªå‹•è™•ç† (æè¿° & è¦æ ¼å°ˆç”¨)")
    
    c_in, c_set = st.columns([1, 1])
    with c_in: uploaded_file = st.file_uploader("ä¸Šå‚³ Excel", type=["xlsx", "xls"], key="up_all")
    with c_set:
        with st.expander("âš™ï¸ è¨­å®š", expanded=True):
            sheet_name = st.text_input("å·¥ä½œè¡¨", "å·¥ä½œè¡¨1", key="sn_all")
            col_idx = st.number_input("å‹è™Ÿæ¬„ä½ç´¢å¼•", value=0, min_value=0, key="mi_all")
            limit = st.number_input("ç²¾ç°¡å­—æ•¸é™åˆ¶", min_value=10, max_value=500, value=50, step=10, key="cl_all")
            autosave_interval = st.number_input("è‡ªå‹•å­˜æª”é »ç‡", min_value=1, max_value=100, value=20, key="as_all")

    # [v3.10] æ–°å¢ï¼šè³‡æ–™é è¦½èˆ‡ç¯©é¸å€
    selected_models_to_process = []
    if uploaded_file:
        try:
            df_preview = pd.read_excel(uploaded_file, sheet_name=sheet_name)
            # æå–æ‰€æœ‰ç¬¦åˆæ ¼å¼çš„å‹è™Ÿ
            all_valid_models = []
            for i, r in df_preview.iterrows():
                if i >= 1 and col_idx < len(r):
                    m = str(r.iloc[col_idx]).strip()
                    if re.match(r'^\d{7}$', m): 
                        all_valid_models.append({"å‹è™Ÿ": m, "åŸå§‹è¡Œæ•¸": i+2, "é¸å–": True}) # é è¨­å…¨é¸
            
            if all_valid_models:
                st.info(f"ğŸ“„ è®€å–åˆ° {len(all_valid_models)} ç­†æœ‰æ•ˆå‹è™Ÿï¼Œè«‹å‹¾é¸æ‚¨è¦è™•ç†çš„é …ç›®ï¼š")
                
                # é¡¯ç¤ºå¯ç·¨è¼¯çš„è¡¨æ ¼ (Data Editor)
                df_selection = pd.DataFrame(all_valid_models)
                edited_df = st.data_editor(
                    df_selection,
                    column_config={
                        "é¸å–": st.column_config.CheckboxColumn(
                            "è™•ç†?",
                            help="å‹¾é¸ä»¥é€²è¡Œè™•ç†",
                            default=True,
                        )
                    },
                    disabled=["å‹è™Ÿ", "åŸå§‹è¡Œæ•¸"],
                    hide_index=True,
                    use_container_width=True,
                    key="editor_all"
                )
                
                # ç²å–ä½¿ç”¨è€…æœ€çµ‚å‹¾é¸çš„å‹è™Ÿ
                selected_models_to_process = edited_df[edited_df["é¸å–"] == True]["å‹è™Ÿ"].tolist()
                st.markdown(f"**âœ… ç›®å‰å·²é¸æ“‡: `{len(selected_models_to_process)}` ç­†**")
                
            else:
                st.warning("âš ï¸ åœ¨æŒ‡å®šçš„æ¬„ä½ä¸­æ‰¾ä¸åˆ°ç¬¦åˆæ ¼å¼ (7ç¢¼æ•¸å­—) çš„å‹è™Ÿï¼Œè«‹æª¢æŸ¥è¨­å®šã€‚")
        except Exception as e:
            st.error(f"è®€å– Excel å¤±æ•—: {e}")

    stop_requested = st.checkbox("ğŸ›‘ ç·Šæ€¥åœæ­¢ (å‹¾é¸å¾Œï¼Œè™•ç†å®Œç•¶å‰ç­†æ•¸å³åœæ­¢)", key="stop_chk")

    # æŒ‰éˆ•é‚è¼¯ï¼šåªæœ‰ç•¶æœ‰é¸æ“‡å‹è™Ÿæ™‚æ‰å•Ÿç”¨
    if st.button("ğŸš€ é–‹å§‹åŸ·è¡Œ", type="primary", use_container_width=True, key="btn_all", disabled=len(selected_models_to_process)==0):
        if not api_key:
            st.error("âŒ è«‹è¼¸å…¥ API Key")
        else:
            try:
                models = selected_models_to_process # ä½¿ç”¨ç¯©é¸å¾Œçš„æ¸…å–®
                results = []
                total = len(models)
                
                status_box = st.status("ğŸš€ ä»»å‹™åˆå§‹åŒ–...", expanded=True)
                prog_bar = st.progress(0)
                
                for i, m in enumerate(models):
                    if stop_requested:
                        status_box.update(label="ğŸ›‘ ä½¿ç”¨è€…è«‹æ±‚åœæ­¢ï¼æ­£åœ¨çµç®—...", state="error")
                        st.warning(f"å·²åœ¨ç¬¬ {i} ç­†åœæ­¢ã€‚")
                        break

                    pct = int((i+1)/total*100)
                    status_box.update(label=f"â³ [{i+1}/{total}] æ­£åœ¨è™•ç†: {m} ({pct}%)")
                    
                    try:
                        # 1. çˆ¬èŸ²
                        raw = scrape_montbell_single(m)
                        
                        row_data = {
                            'å‹è™Ÿ': raw['å‹è™Ÿ'],
                            'å•†å“å': raw['å•†å“å'],
                            'å•†å“URL': raw['å•†å“URL'],
                            'å•†å“æè¿°_åŸæ–‡': raw['å•†å“æè¿°'],
                            'è¦æ ¼_åŸæ–‡': raw['è¦æ ¼'],
                            'å•†å“æè¿°_ç¿»è­¯': '',
                            'è¦æ ¼_ç¿»è­¯': '',
                            'å•†å“æè¿°_AIç²¾ç°¡': '',
                            'è¦æ ¼_AIç²¾ç°¡': ''
                        }

                        # 2. ç¿»è­¯èˆ‡å„ªåŒ–
                        has_data = raw['å•†å“æè¿°'] or raw['è¦æ ¼']
                        
                        if has_data:
                            if raw['å•†å“æè¿°']:
                                desc_res = get_gemini_response(create_trans_prompt(raw['å•†å“æè¿°']), api_key, selected_model)
                                row_data['å•†å“æè¿°_ç¿»è­¯'] = desc_res
                                if "Error" not in desc_res:
                                    row_data['å•†å“æè¿°_AIç²¾ç°¡'] = get_gemini_response(create_refine_prompt(desc_res, limit), api_key, selected_model)

                            if raw['è¦æ ¼']:
                                spec_res = get_gemini_response(create_trans_prompt(raw['è¦æ ¼']), api_key, selected_model)
                                row_data['è¦æ ¼_ç¿»è­¯'] = spec_res
                                if "Error" not in spec_res:
                                    row_data['è¦æ ¼_AIç²¾ç°¡'] = get_gemini_response(create_spec_prompt(spec_res), api_key, selected_model)
                        else:
                            row_data['å•†å“å'] = row_data['å•†å“å'] + " (æŸ¥ç„¡è³‡æ–™)"

                        results.append(row_data)
                        
                        if (i + 1) % autosave_interval == 0:
                            auto_save_to_local(results, "backup_all_in_one.xlsx")
                            st.toast(f"ğŸ’¾ å·²å‚™ä»½ {i+1} ç­†")

                    except Exception as e:
                        st.error(f"è™•ç† {m} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                        auto_save_to_local(results, "backup_error_save.xlsx")
                        continue

                    prog_bar.progress((i+1)/total)
                    time.sleep(0.5)
                
                status_box.update(label="âœ… ä»»å‹™çµæŸï¼", state="complete", expanded=False)
                
                final_cols = ['å‹è™Ÿ', 'å•†å“å', 'å•†å“æè¿°_åŸæ–‡', 'è¦æ ¼_åŸæ–‡', 'å•†å“æè¿°_ç¿»è­¯', 'è¦æ ¼_ç¿»è­¯', 'å•†å“æè¿°_AIç²¾ç°¡', 'è¦æ ¼_AIç²¾ç°¡', 'å•†å“URL']
                df_final = pd.DataFrame(results)
                for col in final_cols:
                    if col not in df_final.columns: df_final[col] = ""
                df_final = df_final[final_cols]

                st.success(f"å…±å®Œæˆ {len(df_final)} ç­†è³‡æ–™ã€‚")
                out = io.BytesIO()
                with pd.ExcelWriter(out, engine='openpyxl') as w: df_final.to_excel(w, index=False)
                st.download_button("ğŸ“¥ ä¸‹è¼‰æœ€çµ‚å ±è¡¨", out.getvalue(), "montbell_final.xlsx", "primary")

            except Exception as e:
                st.error(f"åŸ·è¡ŒéŒ¯èª¤: {e}")

# --- å…¶ä»–é é¢ ---
elif st.session_state.current_page == 'scraper':
    st.markdown("### ğŸ“¥ ç¨ç«‹çˆ¬èŸ² (åƒ…æè¿°èˆ‡è¦æ ¼)")
    up_1 = st.file_uploader("ä¸Šå‚³ Excel", key="up_1")
    c1, c2 = st.columns(2)
    with c1: sheet_1 = st.text_input("å·¥ä½œè¡¨", "å·¥ä½œè¡¨1", key="sn_1")
    with c2: idx_1, row_1 = st.number_input("ç´¢å¼•", 0, key="mi_1"), st.number_input("é–‹å§‹åˆ—", 2, key="sr_1")
    
    # [v3.10] çˆ¬èŸ²é é¢çš„ç¯©é¸
    sel_models_1 = []
    if up_1:
        try:
            df1 = pd.read_excel(up_1, sheet_name=sheet_1)
            valid_m1 = [{"å‹è™Ÿ": str(r.iloc[idx_1]).strip(), "é¸å–": True} for i, r in df1.iterrows() if i>=row_1-1 and idx_1<len(r) and re.match(r'^\d{7}$', str(r.iloc[idx_1]).strip())]
            if valid_m1:
                st.info("å‹¾é¸è¦çˆ¬å–çš„é …ç›®ï¼š")
                ed1 = st.data_editor(pd.DataFrame(valid_m1), key="ed1", hide_index=True, use_container_width=True)
                sel_models_1 = ed1[ed1["é¸å–"]==True]["å‹è™Ÿ"].tolist()
                st.write(f"å·²é¸: {len(sel_models_1)} ç­†")
        except: pass

    stop_1 = st.checkbox("ğŸ›‘ åœæ­¢", key="stop_1")

    if st.button("é–‹å§‹", key="btn_1", disabled=len(sel_models_1)==0):
        try:
            res = []
            prog = st.progress(0)
            for i, m in enumerate(sel_models_1):
                if stop_1: st.warning("å·²åœæ­¢"); break
                res.append(scrape_montbell_single(m))
                if (i+1)%20 == 0: auto_save_to_local(res, "backup_scrape.xlsx")
                prog.progress((i+1)/len(sel_models_1), text=f"é€²åº¦ {int((i+1)/len(sel_models_1)*100)}%")
                time.sleep(0.5)
            out = io.BytesIO()
            with pd.ExcelWriter(out, engine='openpyxl') as w: pd.DataFrame(res).to_excel(w, index=False)
            st.download_button("ä¸‹è¼‰", out.getvalue(), "scraped.xlsx")
        except Exception as e: st.error(f"éŒ¯èª¤: {e}")

elif st.session_state.current_page == 'translator':
    st.markdown("### ğŸˆº ç¨ç«‹ç¿»è­¯")
    up_2 = st.file_uploader("ä¸Šå‚³ Excel", key="up_2")
    
    # [v3.10] ç¿»è­¯é é¢çš„ç¯©é¸
    df_t = pd.DataFrame()
    sel_indices_2 = [] # ç¿»è­¯éœ€è¦è¨˜éŒ„ index
    if up_2:
        try:
            df_t = pd.read_excel(up_2)
            df_t['é¸å–'] = True # é è¨­å…¨é¸
            st.info("å‹¾é¸è¦ç¿»è­¯çš„è³‡æ–™åˆ—ï¼š")
            # é¡¯ç¤ºå‰å¹¾æ¬„ä¾›è¾¨è­˜
            disp_cols = list(df_t.columns[:5]) + ['é¸å–']
            ed2 = st.data_editor(df_t[disp_cols], key="ed2", hide_index=False, use_container_width=True)
            # æ‰¾å‡ºè¢«å‹¾é¸çš„ index
            sel_indices_2 = ed2[ed2['é¸å–']==True].index.tolist()
            st.write(f"å·²é¸: {len(sel_indices_2)} ç­†")
        except: pass

    cols = st.multiselect("ç¿»è­¯æ¬„ä½", df_t.columns if not df_t.empty else [])
    stop_2 = st.checkbox("ğŸ›‘ åœæ­¢", key="stop_2")
    
    if st.button("é–‹å§‹", key="btn_2", disabled=len(sel_indices_2)==0 or not cols):
        if api_key:
            new_df = df_t.copy()
            prog = st.progress(0)
            # è¨ˆç®—ç¸½å·¥ä½œé‡
            total_ops = len(sel_indices_2) * len(cols)
            curr_op = 0
            
            for col in cols:
                new_df[f"{col}_TW"] = "" if f"{col}_TW" not in new_df.columns else new_df[f"{col}_TW"]
                
                for i in sel_indices_2: # åªéæ­·é¸å–çš„ index
                    if stop_2: break
                    val = new_df.at[i, col]
                    if pd.notna(val):
                        res = get_gemini_response(create_trans_prompt(str(val)), api_key, selected_model)
                        new_df.at[i, f"{col}_TW"] = res
                    curr_op += 1
                    if curr_op % 20 == 0: auto_save_to_local(new_df.to_dict('records'), "backup_trans.xlsx")
                    prog.progress(curr_op/total_ops, text=f"{int(curr_op/total_ops*100)}%")
                    time.sleep(0.5)
                if stop_2: break
            
            out = io.BytesIO()
            # åªè¼¸å‡ºé¸å–çš„éƒ¨åˆ†ï¼Œæˆ–æ˜¯å…¨éƒ¨ï¼Ÿé€šå¸¸å¸Œæœ›ä¿ç•™åŸå§‹æª”çµæ§‹ï¼Œæ‰€ä»¥è¼¸å‡ºå…¨éƒ¨ï¼Œä½†åªæœ‰é¸å–çš„æœ‰ç¿»è­¯
            with pd.ExcelWriter(out, engine='openpyxl') as w: new_df.to_excel(w, index=False)
            st.download_button("ä¸‹è¼‰", out.getvalue(), "translated.xlsx")

elif st.session_state.current_page == 'refiner':
    st.markdown("### âœ¨ ç¨ç«‹å„ªåŒ–")
    up_3 = st.file_uploader("ä¸Šå‚³ Excel", key="up_3")
    
    # [v3.10] å„ªåŒ–é é¢çš„ç¯©é¸
    df_r = pd.DataFrame()
    sel_indices_3 = []
    if up_3:
        try:
            df_r = pd.read_excel(up_3)
            df_r['é¸å–'] = True
            st.info("å‹¾é¸è¦å„ªåŒ–çš„è³‡æ–™åˆ—ï¼š")
            disp_cols_r = list(df_r.columns[:5]) + ['é¸å–']
            ed3 = st.data_editor(df_r[disp_cols_r], key="ed3", hide_index=False, use_container_width=True)
            sel_indices_3 = ed3[ed3['é¸å–']==True].index.tolist()
            st.write(f"å·²é¸: {len(sel_indices_3)} ç­†")
        except: pass

    if not df_r.empty:
        c_d = st.selectbox("æè¿°", df_r.columns)
        c_s = st.selectbox("è¦æ ¼", ["(ä¸è™•ç†)"] + list(df_r.columns))
    
    lim = st.slider("å­—æ•¸", 10, 200, 50)
    stop_3 = st.checkbox("ğŸ›‘ åœæ­¢", key="stop_3")
    
    if st.button("é–‹å§‹", key="btn_3", disabled=len(sel_indices_3)==0):
        if api_key:
            # åˆå§‹åŒ–æ¬„ä½
            df_r['ç²¾ç°¡_AI'] = "" if 'ç²¾ç°¡_AI' not in df_r.columns else df_r['ç²¾ç°¡_AI']
            if c_s != "(ä¸è™•ç†)": df_r['è¦æ ¼_AI'] = "" if 'è¦æ ¼_AI' not in df_r.columns else df_r['è¦æ ¼_AI']
            
            prog = st.progress(0)
            total = len(sel_indices_3)
            
            for idx, i in enumerate(sel_indices_3):
                if stop_3: st.warning("å·²åœæ­¢"); break
                
                r = df_r.iloc[i]
                
                # æè¿°
                d_val = get_gemini_response(create_refine_prompt(str(r[c_d]), lim), api_key, selected_model) if pd.notna(r[c_d]) else ""
                if "Error" in d_val: d_val = ""
                df_r.at[i, 'ç²¾ç°¡_AI'] = d_val
                
                # è¦æ ¼
                if c_s != "(ä¸è™•ç†)" and pd.notna(r[c_s]):
                    s_val = get_gemini_response(create_spec_prompt(str(r[c_s])), api_key, selected_model)
                    if "Error" in s_val: s_val = ""
                    df_r.at[i, 'è¦æ ¼_AI'] = s_val
                
                if (idx+1)%20 == 0: auto_save_to_local(df_r.to_dict('records'), "backup_refine.xlsx")
                prog.progress((idx+1)/total, text=f"{int((idx+1)/total*100)}%")
                time.sleep(0.5)
            
            out = io.BytesIO()
            with pd.ExcelWriter(out, engine='openpyxl') as w: df_r.to_excel(w, index=False)
            st.download_button("ä¸‹è¼‰", out.getvalue(), "refined.xlsx")